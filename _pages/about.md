---
permalink: /
title: 
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
<span style="font-size:1.2em;">**Guannan Qu**</span>  
Assistant Professor  
Department of Electrical and Computer Engineering  
Carnegie Mellon University  
Contact: gqu [at] andrew.cmu.edu  
Office: Porter B22


I am an assistant professor at the Department of Electrical and Computer Engineering at Carnegie Mellon University. From 2019 to 2021, I was a CMI and Resnick postdoc in the CMS Department of California Institute of Technology, working with Prof. Steven Low and Prof. Adam Wierman. I obtained my Ph.D. degree from Harvard SEAS working with Prof. Na Li in 2019. I obtained my B.S. degree from Tsinghua University in Beijing, China in 2014. 

I am broadly interested in the theory of control, optimization, learning, and the interplay between control and learning. Particularly, my recent research focuses on developing frameworks and principles that combine methods in model-based control (LQR, robust control, etc.) and model-free RL (Q-learning, policy gradient methods, etc). These two sets of methods are developed based on very different philosophies, yet I believe the two have their unique advantages that complement each other very well, and therefore the combination of the two will yield powerful algorithms that can achieve the best of both worlds. During my Ph.D., I mainly worked on distributed optimization, online control, distributed control, etc. On the practical side, my research is driven by applications like energy/power systems, IoT, transportation systems, robot teams, etc.

**I am actively looking for students, visitors and postdocs to join my group. If you are interested in working with me, feel free to reach out!**

### Recent research highlights
- Learning and control
  - Regret bounds for predictive control of linear time-varying systems ([link](https://arxiv.org/pdf/2106.10497.pdf))
  - Combining model-based and learning based controllers ([paper 1](https://arxiv.org/pdf/2106.09659.pdf), [paper 2](https://arxiv.org/pdf/2006.07476))
- RL for power systems
  - Review paper on RL for power systems ([link](https://arxiv.org/abs/2102.01168))
  - stable RL for voltage control ([link](https://arxiv.org/abs/2109.14854))

- Multi-agent RL for networked systems ([link](https://arxiv.org/abs/1912.02906)), average reward case ([link](https://proceedings.neurips.cc//paper/2020/file/168efc366c449fab9c2843e9b54e2a18-Paper.pdf)), stochastic network case ([link](https://arxiv.org/abs/2006.06555))

### Updates 
- Oct 2021: Our paper on scalable multi-agent RL for networked systems ([link](https://drive.google.com/file/d/1Habyv4j7qUFRuY0jVIFdjc9jthGtXtk_/view?usp=sharing)) has been accepted to *Operations Research*!
- Sept 2021: I am starting at CMU as an assistant professor! 
